---
title: "TwoSample $t$-test as a model comparison"
author: "Andr√© Meichtry"
output:
  html_document:
    number_sections: yes 
    self_contained: yes
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: no
---


```{r chunk_setup, include=FALSE, eval=TRUE}
knitr::opts_chunk$set(echo = T, out.width="49%",message=F, warning=F, comment=NA,
                      eval=T, cache.rebuild=F, cache=F, R.options=list(digits=5,show.signif.stars=FALSE),dev.args=list(bg = 'transparent'))
```


# Simulation of data from model

Simulate some two-group-data from model with parameters $\mu_i$ and $\sigma$ assumed known:

* Means parameterization: $Y_{ij}=\mu_i+\epsilon_{ij}, i=1,2, j=1,...,n_i$, $\boxed{Y_{ij}\sim N(\mu_i,\sigma^2)}$

* Effects parameterization (Default in R): $Y_{ij}=\alpha+I_{group=1}\beta+\epsilon_{ij}$ with
  $\mu_1=\alpha$ and $\beta=\mu_2-\mu_1$.


```{r}
library(psych)
n <- 20
alpha <- 2
beta <- 3
sigma <-10
set.seed(10)
group <- as.factor(sample(c(0,1),n,replace=TRUE))
Y <- alpha+beta*(group==1)+rnorm(n,0,sigma)
headTail(data.frame(Y,group))
```


# Description
```{r}
summary(Y)
by(Y,group,summary)
boxplot(Y~group)
```


# Classical test
```{r }
t.test(Y~group,var.equal=TRUE)
```

# Model approach

## Unrestricted model

$\mu_1$ and $\mu_2$ are unknown and have to be estimated:

```{r}
mod <- lm(Y~group) 
summary(mod)
confint(mod)
```
## Restricted ("Null") model
$H_0: \mu_2-\mu_1=0$ (Means parametrization) or $H_0: \beta=0$ (Effects parameterization). In this case, we have only one mean to be estimated.
```{r}
mod0 <- lm(Y~1) 
summary(mod0)
```
## ANOVA for model comparison
```{r}
anova(mod0,mod)
```
## By hand
### Residual sum of squares and explained sum of squares
```{r}
(RSS <-sum(mod$residuals^2))
(RSS0 <-sum(mod0$residuals^2))
(RSS0-RSS)
```
Multiple R-squared. You find this quantity in the summary model output.

```{r }
(RSS0-RSS)/RSS0
```

### degrees of freedom
```{r}
(df <- n-2)
(df0 <- n-1)
```

### $F$-test
The $F$-statistic is the amount of available fit that is actually achieved,
$$F=\frac{(RSS_0-RSS)/(df_0-df)}{RSS/df}=\frac{"Explained\,Mean Squares"}{"Not\,explained\,Mean Squares"}$$
```{r}
F <- (RSS0-RSS)/(df0-df)/(RSS/(df))
p <- 1-pf(F,df1=df0-df,df2=df)
sigma <- sqrt(RSS/df)
sigma0 <- sqrt(RSS0/df0)
print(data.frame(RSS0,RSS,SSExplained=RSS0-RSS,F,p,sigma,sigma0),row.names=FALSE)
```
## Log-Likelihood of both models*

These are the log-Likelhoods of the model at MLE's (the maximum likelihood estimates).
```{r,eval=FALSE,echo=FALSE}
s <- summary(mod)$sigma
s0 <- summary(mod0)$sigma
sum(log(dnorm(Y,predict(mod),sqrt(s^2*(n-1)/n))))
sum(log(dnorm(Y,predict(mod0),s0)))
```
```{r}
logLik(mod)
logLik(mod0)
```
## AIC and BIC (criterion for optimality)*

Adding penalties for model complexity:
$$AIC=-2l+2p$$ with $l$ as the log-likelihood and $p$ the number of parameters in the model.
$$BIC=-2l+2\log(n)$$
```{r}
AIC(mod0,mod)
BIC(mod0,mod)
```
Smaller AIC and BIC (smaller negative penalized likelihoood) are better. We do NOT reject the constrained model in favor of the unconstrained model. 
